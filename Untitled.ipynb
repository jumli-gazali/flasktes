{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a63d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_name_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 90\u001b[0m\n\u001b[0;32m     86\u001b[0m                 Storage\u001b[38;5;241m.\u001b[39mold_answers\u001b[38;5;241m.\u001b[39mappend(line\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28mprint\u001b[39m (Storage\u001b[38;5;241m.\u001b[39mold_answers)\n\u001b[1;32m---> 90\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[43m_name_\u001b[49m)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbot_response\u001b[39m(userText):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''fake brain'''\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_name_' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# list kosong bernama word, classes, documents\n",
    "words=[] \n",
    "classes = []\n",
    "documents = []\n",
    "# stop word/pengabaian kata\n",
    "ignore_words = ['?', '!'] \n",
    "# load dataset intents\n",
    "data_file = open('intents.json').read() \n",
    "intents = json.loads(data_file)\n",
    "\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "\n",
    "        # Memisahkan setiap kalimat menjadi perkata\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        # menambahkan ke list document\n",
    "        documents.append((w, intent['tag']))\n",
    "\n",
    "        # menambahkan ke list classes\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "\n",
    "# Melakukan case folding dengan dan mengabaikan kata dengan ignore word\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words] \n",
    "words = sorted(list(set(words)))\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))\n",
    "\n",
    "\n",
    "\n",
    "model = load_model('chatbot_model.h5')\n",
    "\n",
    "\n",
    "## end keras chat brain\n",
    "\n",
    "## vars\n",
    "now = time.time() # float\n",
    "\n",
    "filename = str(now)+\"_chatlog.txt\" #create chatlog\n",
    "\n",
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))\n",
    "    \n",
    "## end vars\n",
    "\n",
    "class Storage:\n",
    "    old_answers=[] # storage for old answers\n",
    "    \n",
    "    @classmethod\n",
    "    def save_storage(cls):\n",
    "        with open (\"storage.txt\", \"w\") as myfile:\n",
    "            for answer in Storage.old_answers:\n",
    "                \n",
    "                myfile.write(answer+\"\\n\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_storage(cls):\n",
    "        Storage.old_answers=[]\n",
    "        with open ('storage.txt', 'r') as myfile:\n",
    "            lines = myfile.readlines()\n",
    "            for line in lines:\n",
    "                Storage.old_answers.append(line.strip())\n",
    "        print (Storage.old_answers)\n",
    "\n",
    "\n",
    "app = Flask(_name_)\n",
    "\n",
    "\n",
    "def bot_response(userText):\n",
    "\n",
    "    '''fake brain'''\n",
    "    print (\"your q was: \" + userText)\n",
    "    return \"your q was: \" + userText\n",
    "   \n",
    "## new funcs\n",
    "def clean_up_sentence(sentence):\n",
    "    \"\"\"tokenize/ pisah kalimat menjadi kata\"\"\"\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 atau 1 untuk setiap kata dalam bag yang ada dalam kalimat\n",
    "\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize/pisah kata pada pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s:\n",
    "                # cetak 1 jika kata saat ini berada di posisi kosakata\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"ditemukan pada bag : %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    # filter prediksi dibawah threshold\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    # mengurutkan berdasarkan probabilitas tertinggi\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probabilitas\": str(r[1])})\n",
    "    return return_list\n",
    "    \n",
    "    \n",
    "def getResponse(ints, intents_json):\n",
    "    '''membaca intents file'''\n",
    "    # pseudo code\n",
    "    # menganggap jawaban lama di dalam didalam old_answers\n",
    "    # old_answers = ['response1','response2']\n",
    "\n",
    "    # load old answers ke storage\n",
    "    Storage.load_storage()\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    old_answers = Storage.old_answers  # [:-len(list_of_intents)]\n",
    "    possible_responses = [i['responses'] for i in list_of_intents if i['tag']== tag ][0]\n",
    "    history = Storage.old_answers[-len('kemungkinan response\\n'):]\n",
    "    print(\"** kemungkinan answers dan hriwayat old answers\\n\", possible_responses, \"\\nhistory\\n\", history)\n",
    "    unused_answers = [answer for answer in possible_responses if answer not in history ] # list comprehension\n",
    "    print(\"unused answers\\n\", unused_answers)\n",
    "    unused_two = history[-(len(possible_responses)-1):]\n",
    "    print('5 jawaban terakhir\\n', unused_two)\n",
    "    try:\n",
    "        result = random.choice([answer for answer in possible_responses if answer not in unused_two ])\n",
    "        print(result)\n",
    "    except IndexError:\n",
    "        print(\"Saya kehabisan pilihan, saya akan memilih secara acak.\")\n",
    "        result = random.choice(possible_responses)\n",
    "\n",
    "    Storage.old_answers.append(result) \n",
    "    Storage.old_answers= Storage.old_answers[-20:] \n",
    "    Storage.save_storage()\n",
    "\n",
    "  \n",
    "    return result,tag\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    '''fungai terpenting'''\n",
    "    ints = predict_class(msg, model)\n",
    "    res,tag = getResponse(ints, intents)\n",
    "    return res,tag\n",
    "\n",
    "\n",
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
    "\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"Bot: \" + res + '\\n\\n')\n",
    "\n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    "        # tambah ke log file\n",
    "        with open(filename,'a') as myfile:\n",
    "            myfile.write(\"user: \"+ msg + \"\\n\")\n",
    "            myfile.write(\"bot: \"+ res + \"\\n\")\n",
    "\n",
    "\n",
    "## end new funcs\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "\n",
    "@app.route('/chat')\n",
    "def chat():\n",
    "    return render_template('chat.html')\n",
    "\n",
    "@app.route(\"/get\")\n",
    "def get_bot_response():    \n",
    "    print (\"get is called\")\n",
    "    userText = request.args.get('msg')    \n",
    "    \n",
    "    res,tag = chatbot_response(userText)\n",
    "    with open( \"logfile.csv\", \"a\" ) as logfile:\n",
    "        logfile.write(str(now)+\",\"+userText+\",\"+res+\",\"+tag+\",\"+\"\\n\")\n",
    "    print ('Saya pilih ini : ', res,tag)\n",
    "    #return res + '<p style=\"font-size:8pt;\">tag: ' + tag + '</p>'\n",
    "    return res + '<p style=\"font-size:8pt;\">' + tag + '</p>'\n",
    "\n",
    "\n",
    "\n",
    "if _name_ == '_main_':\n",
    "  app.run()\n",
    "#    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a20d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
